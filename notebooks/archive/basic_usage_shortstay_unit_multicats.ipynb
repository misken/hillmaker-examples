{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using hillmaker (v0.2.0)\n",
    "\n",
    "In this notebook we'll focus on basic use of hillmaker for analyzing occupancy in a typical hospital setting. The data is fictitious data from a hospital short stay unit (SSU). Patients flow through a SSU for a variety of procedures, tests or therapies. Let's assume patients can be classified into one of five categories of patient types: ART (arterialgram), CAT (post cardiac-cath), MYE (myelogram), IVT (IV therapy), and OTH (other). In addition, patients are given a severity score of 1 or 2 which is related to the amount of time required in hte SSU and the level of resources required. From one of our hospital information systems we were able to get raw data about the entry and exit times of each patient along with their patient type and severity values. For simplicity, the data is in a csv file. We are interested in occupancy statistics (e.g. mean, standard deviation, percentiles) by time of day and by day of week. While overall occupancy statistics are important, we are also interested in occupancy statistics for different patient types and severity levels. Since we also are interested in required staffing for this unit, we'll also use hillmaker to analyze workload levels.\n",
    "\n",
    "This example assumes you are already familiar with statistical occupancy analysis using the old version of [Hillmaker](http://hillmaker.sourceforge.net/) or some similar such tool. It also assumes some knowledge of using Python for analytical work.\n",
    "\n",
    "The following blog posts are helpful if you are not familiar with occupancy analysis:\n",
    "\n",
    "* [New version of hillmaker (finally) released - and it's Python ](http://hselab.org/hillmaker-python-released.html)\n",
    "* [Using hillmaker from R with reticulate to analyze time of day patterns in bike share data ](http://hselab.org/r_hillmaker_reticulate.html)\n",
    "* [Computing occupancy statistics with Python - Part 1 of 3](http://nbviewer.ipython.org/github/misken/hselab-tutorials/blob/master/hillpy_bydate_demo.ipynb)\n",
    "* [Computing occupancy statistics with Python - Part 2 of 3](http://nbviewer.ipython.org/github/misken/hselab-tutorials/blob/master/hillpy_occstats_demo.ipynb)\n",
    "\n",
    "## Current status of code\n",
    "The new hillmaker is implemented as a Python module which can be used by importing `hillmaker` and then calling the main hillmaker function, `make_hills()` (or any component function included in the module).  This new version of hillmaker is in what I'd call an alpha state. The output does match the Access version for the ShortStay database that I included in the original Hillmaker. Use at your own risk.\n",
    "\n",
    "It is licensed under an [Apache 2.0 license](http://www.apache.org/licenses/LICENSE-2.0). It is a widely used permissive free software license. See https://en.wikipedia.org/wiki/Apache_License for additional information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "In order to use hillmaker, the major steps are:\n",
    "\n",
    "* make sure you have Python and necessary packages installed,\n",
    "* download and install hillmaker,\n",
    "* load hillmaker and start using it from either a Jupyter notebook, Python terminal or Python script.\n",
    "\n",
    "I'll go through each of these in more detail. As a big part of the audience for this post is former users of the MS Access version of Hillmaker using the Windows OS, many of whom have little experience with tools like Python, I'll try to make the transition as easy as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "Whereas the old Hillmaker required MS Access, the new one requires an installation of \n",
    "Python 3 (3.7+) along \n",
    "with several Python modules that are widely used for analytics and data science work. \n",
    "\n",
    "Most importantly, hillmaker 0.2.0 requires pandas 1.0.0 or later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Python and many analytical packages via Anaconda\n",
    "An very easy way to get Python 3 pre-configured with tons of analytical Python packages is to use the Anaconda distro for Python. From their [Downloads page](https://www.continuum.io/downloads):\n",
    "\n",
    "> Anaconda is a completely free Python distribution (including for commercial use and redistribution). \n",
    "> It includes more than 300 of the most popular Python packages for science, math, engineering, and \n",
    "> data analysis. See the packages included with Anaconda and the Anaconda changelog.\n",
    "    \n",
    "There are several really nice reasons to use the Anaconda Python distro for data science work:\n",
    "\n",
    "- it comes preconfigured with hundreds of the most popular data science Python packages installed and they just work\n",
    "- large community of Anaconda data science users and vibrant user community on places like StackOverflow\n",
    "- it has a companion package manager called Conda which makes it easy to install new packages as well as to create and manage virtual environments\n",
    "\n",
    "If you use Anaconda, you already have all of the necessary libraries for using hillmaker other than hillmaker itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Hillmaker\n",
    "\n",
    "Since 2016, hillmaker has been freely available from the Python Package Index known as [PyPi](https://pypi.python.org/pypi) as well as [Anaconda Cloud](http://anaconda.org/). They are similar to CRAN for R. Source code is also be available from my GitHub site https://github.com/misken/hillmaker and it is an open-source project. If you work with Python, you should know a little bit about [Python package installation](https://docs.python.org/3/installing/). There is already a companion project on GitHub called `hillmaker-examples` which contains, well, examples of hillmaker use cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Hillmaker\n",
    "\n",
    "You can use either `pip` or `conda` to install hillmaker. I suggest learning about Python virtual environments and either using `pyenv`, `virtualenv` or `conda` (preferred) to create a Python virtual environment and then install hillmaker into it. This way you avoid mixing developmental third-party packages like hillmaker with your base Anaconda Python environment. \n",
    "\n",
    "\n",
    "#### Step 1 - Open a terminal and install using Conda or Pip\n",
    "\n",
    "To install using  `conda`:\n",
    "\n",
    "```sh\n",
    "conda install -c https://conda.anaconda.org/hselab hillmaker\n",
    "```\n",
    "\n",
    "OR\n",
    "\n",
    "To install using  `pip`:\n",
    "\n",
    "```sh\n",
    "pip install hillmaker\n",
    "```\n",
    "\n",
    "#### Step 2 - Confirm that hillmaker was installed\n",
    "\n",
    "Use the `conda list` command to see all the installed packages in your Anaconda3 root.\n",
    "\n",
    "```sh\n",
    "conda list\n",
    "```\n",
    "\n",
    "You should see hillmaker in the listing.\n",
    "\n",
    "#### Step 3 - Confirm that hillmaker can be loaded\n",
    "\n",
    "Now fire up a Python session (just type python at a Linux/Mac shell or a Windows Anaconda command prompt) and try:\n",
    "\n",
    "    import hillmaker as hm \n",
    "\n",
    "If the install went well, you shouldn't get any errors when you import hillmaker. To see the main help docstring, do the following at your Python prompt:\n",
    "\n",
    "    help(hm.make_hills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using hillmaker\n",
    "The rest of this Jupyter notebook will illustrate a few ways to use the `hillmaker` package to analyze occupancy in our SSU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module imports\n",
    "To run Hillmaker we only need to import a few modules. Since the main Hillmaker function uses Pandas DataFrames for both data input and output, we need to import `pandas` in addition to `hillmaker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hillmaker as hm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read main data file containing patient visits to short stay unit\n",
    "Here's the first few lines from our csv file containing the patient stop data:\n",
    "\n",
    "    PatID,InRoomTS,OutRoomTS,PatType,Severity,PatTypeSeverity\n",
    "    1,01/01/96 07:44 AM,01/01/96 08:50 AM,IVT,1,IVT_1\n",
    "    2,01/01/96 08:28 AM,01/01/96 09:20 AM,IVT,1,IVT_1\n",
    "    3,01/01/96 11:44 AM,01/01/96 01:30 PM,MYE,1,MYE_1\n",
    "    4,01/01/96 11:51 AM,01/01/96 12:55 PM,CAT,1,CAT_1\n",
    "    5,01/01/96 12:10 PM,01/01/96 01:00 PM,IVT,2,IVT_2\n",
    "\n",
    "\n",
    "Read the short stay data from a csv file into a DataFrame and tell Pandas which fields to treat as dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59877 entries, 0 to 59876\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   PatID            59877 non-null  int64         \n",
      " 1   InRoomTS         59877 non-null  datetime64[ns]\n",
      " 2   OutRoomTS        59877 non-null  datetime64[ns]\n",
      " 3   PatType          59877 non-null  object        \n",
      " 4   Severity         59877 non-null  int64         \n",
      " 5   PatTypeSeverity  59877 non-null  object        \n",
      "dtypes: datetime64[ns](2), int64(2), object(2)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "file_stopdata = '../data/ShortStay2.csv'\n",
    "stops_df = pd.read_csv(file_stopdata, parse_dates=['InRoomTS','OutRoomTS'])\n",
    "stops_df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the top and bottom of `stops_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatID</th>\n",
       "      <th>InRoomTS</th>\n",
       "      <th>OutRoomTS</th>\n",
       "      <th>PatType</th>\n",
       "      <th>Severity</th>\n",
       "      <th>PatTypeSeverity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1996-01-01 07:44:00</td>\n",
       "      <td>1996-01-01 08:50:00</td>\n",
       "      <td>IVT</td>\n",
       "      <td>1</td>\n",
       "      <td>IVT_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1996-01-01 08:28:00</td>\n",
       "      <td>1996-01-01 09:20:00</td>\n",
       "      <td>IVT</td>\n",
       "      <td>1</td>\n",
       "      <td>IVT_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1996-01-01 11:44:00</td>\n",
       "      <td>1996-01-01 13:30:00</td>\n",
       "      <td>MYE</td>\n",
       "      <td>1</td>\n",
       "      <td>MYE_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1996-01-01 11:51:00</td>\n",
       "      <td>1996-01-01 12:55:00</td>\n",
       "      <td>CAT</td>\n",
       "      <td>1</td>\n",
       "      <td>CAT_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1996-01-01 12:10:00</td>\n",
       "      <td>1996-01-01 13:00:00</td>\n",
       "      <td>IVT</td>\n",
       "      <td>2</td>\n",
       "      <td>IVT_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1996-01-01 14:16:00</td>\n",
       "      <td>1996-01-01 15:35:00</td>\n",
       "      <td>IVT</td>\n",
       "      <td>2</td>\n",
       "      <td>IVT_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1996-01-01 14:40:00</td>\n",
       "      <td>1996-01-01 15:25:00</td>\n",
       "      <td>IVT</td>\n",
       "      <td>2</td>\n",
       "      <td>IVT_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatID            InRoomTS           OutRoomTS PatType  Severity  \\\n",
       "0      1 1996-01-01 07:44:00 1996-01-01 08:50:00     IVT         1   \n",
       "1      2 1996-01-01 08:28:00 1996-01-01 09:20:00     IVT         1   \n",
       "2      3 1996-01-01 11:44:00 1996-01-01 13:30:00     MYE         1   \n",
       "3      4 1996-01-01 11:51:00 1996-01-01 12:55:00     CAT         1   \n",
       "4      5 1996-01-01 12:10:00 1996-01-01 13:00:00     IVT         2   \n",
       "5      6 1996-01-01 14:16:00 1996-01-01 15:35:00     IVT         2   \n",
       "6      7 1996-01-01 14:40:00 1996-01-01 15:25:00     IVT         2   \n",
       "\n",
       "  PatTypeSeverity  \n",
       "0           IVT_1  \n",
       "1           IVT_1  \n",
       "2           MYE_1  \n",
       "3           CAT_1  \n",
       "4           IVT_2  \n",
       "5           IVT_2  \n",
       "6           IVT_2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatID</th>\n",
       "      <th>InRoomTS</th>\n",
       "      <th>OutRoomTS</th>\n",
       "      <th>PatType</th>\n",
       "      <th>Severity</th>\n",
       "      <th>PatTypeSeverity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59872</th>\n",
       "      <td>59873</td>\n",
       "      <td>1996-09-30 19:31:00</td>\n",
       "      <td>1996-09-30 20:15:00</td>\n",
       "      <td>IVT</td>\n",
       "      <td>1</td>\n",
       "      <td>IVT_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59873</th>\n",
       "      <td>59874</td>\n",
       "      <td>1996-09-30 20:23:00</td>\n",
       "      <td>1996-09-30 21:30:00</td>\n",
       "      <td>IVT</td>\n",
       "      <td>2</td>\n",
       "      <td>IVT_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59874</th>\n",
       "      <td>59875</td>\n",
       "      <td>1996-09-30 21:00:00</td>\n",
       "      <td>1996-09-30 22:45:00</td>\n",
       "      <td>CAT</td>\n",
       "      <td>1</td>\n",
       "      <td>CAT_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59875</th>\n",
       "      <td>59876</td>\n",
       "      <td>1996-09-30 21:57:00</td>\n",
       "      <td>1996-09-30 22:40:00</td>\n",
       "      <td>IVT</td>\n",
       "      <td>2</td>\n",
       "      <td>IVT_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59876</th>\n",
       "      <td>59877</td>\n",
       "      <td>1996-09-30 22:45:00</td>\n",
       "      <td>1996-09-30 23:35:00</td>\n",
       "      <td>CAT</td>\n",
       "      <td>1</td>\n",
       "      <td>CAT_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PatID            InRoomTS           OutRoomTS PatType  Severity  \\\n",
       "59872  59873 1996-09-30 19:31:00 1996-09-30 20:15:00     IVT         1   \n",
       "59873  59874 1996-09-30 20:23:00 1996-09-30 21:30:00     IVT         2   \n",
       "59874  59875 1996-09-30 21:00:00 1996-09-30 22:45:00     CAT         1   \n",
       "59875  59876 1996-09-30 21:57:00 1996-09-30 22:40:00     IVT         2   \n",
       "59876  59877 1996-09-30 22:45:00 1996-09-30 23:35:00     CAT         1   \n",
       "\n",
       "      PatTypeSeverity  \n",
       "59872           IVT_1  \n",
       "59873           IVT_2  \n",
       "59874           CAT_1  \n",
       "59875           IVT_2  \n",
       "59876           CAT_1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancement to handle multiple categorical fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `PatType` field are strings while `Severity` is integer data. In the previous version of hillmaker (v0.1.1), you could only specify a single category field and it needed to be of type string. So, to compute occupancy statistics by `Severity` required some data wrangling (convert int to string) and to analyze occupancy by `PatType` and `Severity` required further wrangling to concatenate the two fields into a single field that we could feed to hillmaker. Note in the output above that I've included an example of such a concatenation just for illustration purposes. \n",
    "\n",
    "In this latest version, you can specify zero or more categorical fields which can either be string or integer data types. There is no need to create a concatenated version such as the `PatTypeSeverity` field above. We'll see that you also have finer control over category field subtotaling.\n",
    "\n",
    "Let's do some counts of patients by the two categorical fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatType\n",
       "ART     5761\n",
       "CAT    10692\n",
       "IVT    33179\n",
       "MYE     6478\n",
       "OTH     3767\n",
       "Name: PatID, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops_df.groupby('PatType')['PatID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Severity\n",
       "1    23803\n",
       "2    36074\n",
       "Name: PatID, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops_df.groupby('Severity')['PatID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obvious problems. We'll assume the data was all read in correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating occupancy summaries\n",
    "The primary function in Hillmaker is called `make_hills` and plays the same role as the `Hillmaker` function in the original Access VBA version of Hillmaker. Let's get a little help on this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function make_hills in module hillmaker.hills:\n",
      "\n",
      "make_hills(scenario_name, stops_df, infield, outfield, start_analysis, end_analysis, catfield=None, bin_size_minutes=60, percentiles=(0.25, 0.5, 0.75, 0.95, 0.99), cat_to_exclude=None, occ_weight_field=None, totals=1, nonstationary_stats=True, stationary_stats=True, export_bydatetime_csv=True, export_summaries_csv=True, export_path='.', edge_bins=1, verbose=0)\n",
      "    Compute occupancy, arrival, and departure statistics by time bin of day and day of week.\n",
      "    \n",
      "    Main function that first calls `bydatetime.make_bydatetime` to calculate occupancy, arrival\n",
      "    and departure values by date by time bin and then calls `summarize.summarize`\n",
      "    to compute the summary statistics.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    \n",
      "    scenario_name : string\n",
      "        Used in output filenames\n",
      "    stops_df : DataFrame\n",
      "        Base data containing one row per visit\n",
      "    infield : string\n",
      "        Column name corresponding to the arrival times\n",
      "    outfield : string\n",
      "        Column name corresponding to the departure times\n",
      "    start_analysis : datetime-like, str\n",
      "        Starting datetime for the analysis (must be convertible to pandas Timestamp)\n",
      "    end_analysis : datetime-like, str\n",
      "        Ending datetime for the analysis (must be convertible to pandas Timestamp)\n",
      "    catfield : string or List of strings, optional\n",
      "        Column name(s) corresponding to the categories. If none is specified, then only overall occupancy is analyzed.\n",
      "        Default is None\n",
      "    bin_size_minutes : int, optional\n",
      "        Number of minutes in each time bin of the day, default is 60\n",
      "    percentiles : list or tuple of floats (e.g. [0.5, 0.75, 0.95]), optional\n",
      "        Which percentiles to compute. Default is (0.25, 0.5, 0.75, 0.95, 0.99)\n",
      "    cat_to_exclude : list, optional\n",
      "        Categories to ignore, default is None\n",
      "    occ_weight_field : string, optional\n",
      "        Column name corresponding to the weights to use for occupancy incrementing.\n",
      "    edge_bins: int, default 1\n",
      "        Occupancy contribution method for arrival and departure bins. 1=fractional, 2=whole bin\n",
      "    totals: int, default 1\n",
      "        0=no totals, 1=totals by datetime, 2=totals bydatetime as well as totals for each field in the\n",
      "        catfields (only relevant for > 1 category field)\n",
      "    nonstationary_stats : bool, optional\n",
      "       If True, datetime bin stats are computed. Else, they aren't computed. Default is True\n",
      "    stationary_stats : bool, optional\n",
      "       If True, overall, non time bin dependent, stats are computed. Else, they aren't computed. Default is True\n",
      "    export_bydatetime_csv : bool, optional\n",
      "       If True, bydatetime DataFrames are exported to csv files. Default is True.\n",
      "    export_summaries_csv : bool, optional\n",
      "       If True, summary DataFrames are exported to csv files. Default is True.\n",
      "    export_path : string, optional\n",
      "        Destination path for exported csv files, default is current directory\n",
      "    verbose : int, optional\n",
      "        The verbosity level. The default, zero, means silent mode. Higher numbers mean more output messages.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    dict of DataFrames\n",
      "       The bydatetime DataFrames and all summary DataFrames. The hierarchy of keys in the\n",
      "       dictionary is:\n",
      "    \n",
      "    \n",
      "    \n",
      "       Example:\n",
      "    \n",
      "       {'bydatetime': bydt_df,\n",
      "        'occupancy': occ_stats_summary,\n",
      "        'arrivals': arr_stats_summary,\n",
      "        'departures': dep_stats_summary,\n",
      "        'tot_occ': occ_stats_summary_cat,\n",
      "        'tot_arr': arr_stats_summary_cat,\n",
      "        'tot_dep': dep_stats_summary_cat}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hm.make_hills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the parameters are similar to those in the original VBA version, though a few new ones have been added. Since the VBA version used an Access database as the container for its output, new parameters were added to control output to csv files  and/or pandas DataFrames instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: 60 minute bins, PatientType and Severity, export to csv\n",
    "Specify values for all the required inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Required inputs\n",
    "scenario = 'example1'\n",
    "in_fld_name = 'InRoomTS'\n",
    "out_fld_name = 'OutRoomTS'\n",
    "start = '1/1/1996'\n",
    "end = '3/30/1996 23:45'\n",
    "\n",
    "# Optional inputs\n",
    "cat_fld_name = ['PatType', 'Severity']\n",
    "verbose = 1\n",
    "output = './output'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll call the main `make_hills` function. We won't capture the return values but will simply take the default behavior of having the summaries exported to csv files. You'll see that the filenames will contain the scenario value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min of intime: 1996-01-01 07:44:00\n",
      "max of intime: 1996-09-30 22:45:00\n",
      "min of outtime: 1996-01-01 08:50:00\n",
      "max of outtime: 1996-09-30 23:35:00\n",
      "19795 stop records processed.\n",
      "Datetime DataFrame created (seconds): 23.6405\n",
      "Created nonstationary summaries - ['PatType', 'Severity']\n",
      "Created nonstationary summaries - []\n",
      "Created stationary summaries - ['PatType', 'Severity']\n",
      "Created stationary summaries - []\n",
      "Summaries by datetime created (seconds): 59.6484\n",
      "By datetime exported to csv (seconds): 0.1643\n",
      "Summaries exported to csv (seconds): 0.1832\n",
      "Total time (seconds): 83.6367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bydatetime': {'PatType_Severity_datetime':                                       arrivals  departures  occupancy  \\\n",
       "  PatType Severity datetime                                               \n",
       "  ART     1        1996-01-01 00:00:00       0.0         0.0        0.0   \n",
       "                   1996-01-01 01:00:00       0.0         0.0        0.0   \n",
       "                   1996-01-01 02:00:00       0.0         0.0        0.0   \n",
       "                   1996-01-01 03:00:00       0.0         0.0        0.0   \n",
       "                   1996-01-01 04:00:00       0.0         0.0        0.0   \n",
       "  ...                                        ...         ...        ...   \n",
       "  OTH     2        1996-03-30 19:00:00       0.0         0.0        0.0   \n",
       "                   1996-03-30 20:00:00       0.0         0.0        0.0   \n",
       "                   1996-03-30 21:00:00       0.0         0.0        0.0   \n",
       "                   1996-03-30 22:00:00       0.0         0.0        0.0   \n",
       "                   1996-03-30 23:00:00       0.0         0.0        0.0   \n",
       "  \n",
       "                                        day_of_week  dow_name  bin_of_day  \\\n",
       "  PatType Severity datetime                                                 \n",
       "  ART     1        1996-01-01 00:00:00            0    Monday           0   \n",
       "                   1996-01-01 01:00:00            0    Monday           1   \n",
       "                   1996-01-01 02:00:00            0    Monday           2   \n",
       "                   1996-01-01 03:00:00            0    Monday           3   \n",
       "                   1996-01-01 04:00:00            0    Monday           4   \n",
       "  ...                                           ...       ...         ...   \n",
       "  OTH     2        1996-03-30 19:00:00            5  Saturday          19   \n",
       "                   1996-03-30 20:00:00            5  Saturday          20   \n",
       "                   1996-03-30 21:00:00            5  Saturday          21   \n",
       "                   1996-03-30 22:00:00            5  Saturday          22   \n",
       "                   1996-03-30 23:00:00            5  Saturday          23   \n",
       "  \n",
       "                                        bin_of_week  \n",
       "  PatType Severity datetime                          \n",
       "  ART     1        1996-01-01 00:00:00            0  \n",
       "                   1996-01-01 01:00:00            1  \n",
       "                   1996-01-01 02:00:00            2  \n",
       "                   1996-01-01 03:00:00            3  \n",
       "                   1996-01-01 04:00:00            4  \n",
       "  ...                                           ...  \n",
       "  OTH     2        1996-03-30 19:00:00          139  \n",
       "                   1996-03-30 20:00:00          140  \n",
       "                   1996-03-30 21:00:00          141  \n",
       "                   1996-03-30 22:00:00          142  \n",
       "                   1996-03-30 23:00:00          143  \n",
       "  \n",
       "  [21600 rows x 7 columns],\n",
       "  'datetime':                      arrivals  departures  occupancy  day_of_week  dow_name  \\\n",
       "  datetime                                                                      \n",
       "  1996-01-01 00:00:00       0.0         0.0        0.0            0    Monday   \n",
       "  1996-01-01 01:00:00       0.0         0.0        0.0            0    Monday   \n",
       "  1996-01-01 02:00:00       0.0         0.0        0.0            0    Monday   \n",
       "  1996-01-01 03:00:00       0.0         0.0        0.0            0    Monday   \n",
       "  1996-01-01 04:00:00       0.0         0.0        0.0            0    Monday   \n",
       "  ...                       ...         ...        ...          ...       ...   \n",
       "  1996-03-30 19:00:00       0.0         0.0        0.0            5  Saturday   \n",
       "  1996-03-30 20:00:00       0.0         0.0        0.0            5  Saturday   \n",
       "  1996-03-30 21:00:00       0.0         0.0        0.0            5  Saturday   \n",
       "  1996-03-30 22:00:00       0.0         0.0        0.0            5  Saturday   \n",
       "  1996-03-30 23:00:00       0.0         0.0        0.0            5  Saturday   \n",
       "  \n",
       "                       bin_of_day  bin_of_week  \n",
       "  datetime                                      \n",
       "  1996-01-01 00:00:00           0            0  \n",
       "  1996-01-01 01:00:00           1            1  \n",
       "  1996-01-01 02:00:00           2            2  \n",
       "  1996-01-01 03:00:00           3            3  \n",
       "  1996-01-01 04:00:00           4            4  \n",
       "  ...                         ...          ...  \n",
       "  1996-03-30 19:00:00          19          139  \n",
       "  1996-03-30 20:00:00          20          140  \n",
       "  1996-03-30 21:00:00          21          141  \n",
       "  1996-03-30 22:00:00          22          142  \n",
       "  1996-03-30 23:00:00          23          143  \n",
       "  \n",
       "  [2160 rows x 7 columns]},\n",
       " 'summaries': {'nonstationary': {'PatType_Severity_dow_binofday': {'occupancy':                                                   count  mean  min  max  \\\n",
       "    PatType Severity day_of_week dow_name bin_of_day                          \n",
       "    ART     1        0           Monday   0            13.0   0.0  0.0  0.0   \n",
       "                                          1            13.0   0.0  0.0  0.0   \n",
       "                                          2            13.0   0.0  0.0  0.0   \n",
       "                                          3            13.0   0.0  0.0  0.0   \n",
       "                                          4            13.0   0.0  0.0  0.0   \n",
       "    ...                                                 ...   ...  ...  ...   \n",
       "    OTH     2        6           Sunday   19           12.0   0.0  0.0  0.0   \n",
       "                                          20           12.0   0.0  0.0  0.0   \n",
       "                                          21           12.0   0.0  0.0  0.0   \n",
       "                                          22           12.0   0.0  0.0  0.0   \n",
       "                                          23           12.0   0.0  0.0  0.0   \n",
       "    \n",
       "                                                      stdev  sem  var   cv  skew  \\\n",
       "    PatType Severity day_of_week dow_name bin_of_day                               \n",
       "    ART     1        0           Monday   0             0.0  0.0  0.0  0.0   0.0   \n",
       "                                          1             0.0  0.0  0.0  0.0   0.0   \n",
       "                                          2             0.0  0.0  0.0  0.0   0.0   \n",
       "                                          3             0.0  0.0  0.0  0.0   0.0   \n",
       "                                          4             0.0  0.0  0.0  0.0   0.0   \n",
       "    ...                                                 ...  ...  ...  ...   ...   \n",
       "    OTH     2        6           Sunday   19            0.0  0.0  0.0  0.0   0.0   \n",
       "                                          20            0.0  0.0  0.0  0.0   0.0   \n",
       "                                          21            0.0  0.0  0.0  0.0   0.0   \n",
       "                                          22            0.0  0.0  0.0  0.0   0.0   \n",
       "                                          23            0.0  0.0  0.0  0.0   0.0   \n",
       "    \n",
       "                                                      kurt  p25  p50  p75  p95  \\\n",
       "    PatType Severity day_of_week dow_name bin_of_day                             \n",
       "    ART     1        0           Monday   0            0.0  0.0  0.0  0.0  0.0   \n",
       "                                          1            0.0  0.0  0.0  0.0  0.0   \n",
       "                                          2            0.0  0.0  0.0  0.0  0.0   \n",
       "                                          3            0.0  0.0  0.0  0.0  0.0   \n",
       "                                          4            0.0  0.0  0.0  0.0  0.0   \n",
       "    ...                                                ...  ...  ...  ...  ...   \n",
       "    OTH     2        6           Sunday   19           0.0  0.0  0.0  0.0  0.0   \n",
       "                                          20           0.0  0.0  0.0  0.0  0.0   \n",
       "                                          21           0.0  0.0  0.0  0.0  0.0   \n",
       "                                          22           0.0  0.0  0.0  0.0  0.0   \n",
       "                                          23           0.0  0.0  0.0  0.0  0.0   \n",
       "    \n",
       "                                                      p99  \n",
       "    PatType Severity day_of_week dow_name bin_of_day       \n",
       "    ART     1        0           Monday   0           0.0  \n",
       "                                          1           0.0  \n",
       "                                          2           0.0  \n",
       "                                          3           0.0  \n",
       "                                          4           0.0  \n",
       "    ...                                               ...  \n",
       "    OTH     2        6           Sunday   19          0.0  \n",
       "                                          20          0.0  \n",
       "                                          21          0.0  \n",
       "                                          22          0.0  \n",
       "                                          23          0.0  \n",
       "    \n",
       "    [1680 rows x 15 columns],\n",
       "    'arrivals':                                                   count  mean  min  max  \\\n",
       "    PatType Severity day_of_week dow_name bin_of_day                          \n",
       "    ART     1        0           Monday   0            13.0   0.0  0.0  0.0   \n",
       "                                          1            13.0   0.0  0.0  0.0   \n",
       "                                          2            13.0   0.0  0.0  0.0   \n",
       "                                          3            13.0   0.0  0.0  0.0   \n",
       "                                          4            13.0   0.0  0.0  0.0   \n",
       "    ...                                                 ...   ...  ...  ...   \n",
       "    OTH     2        6           Sunday   19           12.0   0.0  0.0  0.0   \n",
       "                                          20           12.0   0.0  0.0  0.0   \n",
       "                                          21           12.0   0.0  0.0  0.0   \n",
       "                                          22           12.0   0.0  0.0  0.0   \n",
       "                                          23           12.0   0.0  0.0  0.0   \n",
       "    \n",
       "                                                      stdev  sem  var   cv  skew  \\\n",
       "    PatType Severity day_of_week dow_name bin_of_day                               \n",
       "    ART     1        0           Monday   0             0.0  0.0  0.0  0.0   0.0   \n",
       "                                          1             0.0  0.0  0.0  0.0   0.0   \n",
       "                                          2             0.0  0.0  0.0  0.0   0.0   \n",
       "                                          3             0.0  0.0  0.0  0.0   0.0   \n",
       "                                          4             0.0  0.0  0.0  0.0   0.0   \n",
       "    ...                                                 ...  ...  ...  ...   ...   \n",
       "    OTH     2        6           Sunday   19            0.0  0.0  0.0  0.0   0.0   \n",
       "                                          20            0.0  0.0  0.0  0.0   0.0   \n",
       "                                          21            0.0  0.0  0.0  0.0   0.0   \n",
       "                                          22            0.0  0.0  0.0  0.0   0.0   \n",
       "                                          23            0.0  0.0  0.0  0.0   0.0   \n",
       "    \n",
       "                                                      kurt  p25  p50  p75  p95  \\\n",
       "    PatType Severity day_of_week dow_name bin_of_day                             \n",
       "    ART     1        0           Monday   0            0.0  0.0  0.0  0.0  0.0   \n",
       "                                          1            0.0  0.0  0.0  0.0  0.0   \n",
       "                                          2            0.0  0.0  0.0  0.0  0.0   \n",
       "                                          3            0.0  0.0  0.0  0.0  0.0   \n",
       "                                          4            0.0  0.0  0.0  0.0  0.0   \n",
       "    ...                                                ...  ...  ...  ...  ...   \n",
       "    OTH     2        6           Sunday   19           0.0  0.0  0.0  0.0  0.0   \n",
       "                                          20           0.0  0.0  0.0  0.0  0.0   \n",
       "                                          21           0.0  0.0  0.0  0.0  0.0   \n",
       "                                          22           0.0  0.0  0.0  0.0  0.0   \n",
       "                                          23           0.0  0.0  0.0  0.0  0.0   \n",
       "    \n",
       "                                                      p99  \n",
       "    PatType Severity day_of_week dow_name bin_of_day       \n",
       "    ART     1        0           Monday   0           0.0  \n",
       "                                          1           0.0  \n",
       "                                          2           0.0  \n",
       "                                          3           0.0  \n",
       "                                          4           0.0  \n",
       "    ...                                               ...  \n",
       "    OTH     2        6           Sunday   19          0.0  \n",
       "                                          20          0.0  \n",
       "                                          21          0.0  \n",
       "                                          22          0.0  \n",
       "                                          23          0.0  \n",
       "    \n",
       "    [1680 rows x 15 columns],\n",
       "    'departures':                                                   count  mean  min  max  \\\n",
       "    PatType Severity day_of_week dow_name bin_of_day                          \n",
       "    ART     1        0           Monday   0            13.0   0.0  0.0  0.0   \n",
       "                                          1            13.0   0.0  0.0  0.0   \n",
       "                                          2            13.0   0.0  0.0  0.0   \n",
       "                                          3            13.0   0.0  0.0  0.0   \n",
       "                                          4            13.0   0.0  0.0  0.0   \n",
       "    ...                                                 ...   ...  ...  ...   \n",
       "    OTH     2        6           Sunday   19           12.0   0.0  0.0  0.0   \n",
       "                                          20           12.0   0.0  0.0  0.0   \n",
       "                                          21           12.0   0.0  0.0  0.0   \n",
       "                                          22           12.0   0.0  0.0  0.0   \n",
       "                                          23           12.0   0.0  0.0  0.0   \n",
       "    \n",
       "                                                      stdev  sem  var   cv  skew  \\\n",
       "    PatType Severity day_of_week dow_name bin_of_day                               \n",
       "    ART     1        0           Monday   0             0.0  0.0  0.0  0.0   0.0   \n",
       "                                          1             0.0  0.0  0.0  0.0   0.0   \n",
       "                                          2             0.0  0.0  0.0  0.0   0.0   \n",
       "                                          3             0.0  0.0  0.0  0.0   0.0   \n",
       "                                          4             0.0  0.0  0.0  0.0   0.0   \n",
       "    ...                                                 ...  ...  ...  ...   ...   \n",
       "    OTH     2        6           Sunday   19            0.0  0.0  0.0  0.0   0.0   \n",
       "                                          20            0.0  0.0  0.0  0.0   0.0   \n",
       "                                          21            0.0  0.0  0.0  0.0   0.0   \n",
       "                                          22            0.0  0.0  0.0  0.0   0.0   \n",
       "                                          23            0.0  0.0  0.0  0.0   0.0   \n",
       "    \n",
       "                                                      kurt  p25  p50  p75  p95  \\\n",
       "    PatType Severity day_of_week dow_name bin_of_day                             \n",
       "    ART     1        0           Monday   0            0.0  0.0  0.0  0.0  0.0   \n",
       "                                          1            0.0  0.0  0.0  0.0  0.0   \n",
       "                                          2            0.0  0.0  0.0  0.0  0.0   \n",
       "                                          3            0.0  0.0  0.0  0.0  0.0   \n",
       "                                          4            0.0  0.0  0.0  0.0  0.0   \n",
       "    ...                                                ...  ...  ...  ...  ...   \n",
       "    OTH     2        6           Sunday   19           0.0  0.0  0.0  0.0  0.0   \n",
       "                                          20           0.0  0.0  0.0  0.0  0.0   \n",
       "                                          21           0.0  0.0  0.0  0.0  0.0   \n",
       "                                          22           0.0  0.0  0.0  0.0  0.0   \n",
       "                                          23           0.0  0.0  0.0  0.0  0.0   \n",
       "    \n",
       "                                                      p99  \n",
       "    PatType Severity day_of_week dow_name bin_of_day       \n",
       "    ART     1        0           Monday   0           0.0  \n",
       "                                          1           0.0  \n",
       "                                          2           0.0  \n",
       "                                          3           0.0  \n",
       "                                          4           0.0  \n",
       "    ...                                               ...  \n",
       "    OTH     2        6           Sunday   19          0.0  \n",
       "                                          20          0.0  \n",
       "                                          21          0.0  \n",
       "                                          22          0.0  \n",
       "                                          23          0.0  \n",
       "    \n",
       "    [1680 rows x 15 columns]},\n",
       "   'dow_binofday': {'occupancy':                                  count      mean  min       max     stdev  \\\n",
       "    day_of_week dow_name bin_of_day                                             \n",
       "    0           Monday   0            13.0  0.292308  0.0  0.766667  0.310437   \n",
       "                         1            13.0  0.260256  0.0  1.000000  0.371965   \n",
       "                         2            13.0  0.361538  0.0  0.916667  0.387919   \n",
       "                         3            13.0  0.057692  0.0  0.416667  0.129030   \n",
       "                         4            13.0  0.067949  0.0  0.883333  0.244993   \n",
       "    ...                                ...       ...  ...       ...       ...   \n",
       "    6           Sunday   19           12.0  0.668056  0.0  3.266667  0.977718   \n",
       "                         20           12.0  0.726389  0.0  2.000000  0.637524   \n",
       "                         21           12.0  0.375000  0.0  1.000000  0.374941   \n",
       "                         22           12.0  0.293056  0.0  1.333333  0.453964   \n",
       "                         23           12.0  0.240278  0.0  0.833333  0.344983   \n",
       "    \n",
       "                                          sem       var        cv      skew  \\\n",
       "    day_of_week dow_name bin_of_day                                           \n",
       "    0           Monday   0           0.086100  0.096371  1.062021  0.323427   \n",
       "                         1           0.103165  0.138358  1.429227  1.308016   \n",
       "                         2           0.107589  0.150481  1.072966  0.393781   \n",
       "                         3           0.035787  0.016649  2.236528  2.359507   \n",
       "                         4           0.067949  0.060021  3.605551  3.605551   \n",
       "    ...                                   ...       ...       ...       ...   \n",
       "    6           Sunday   19          0.282243  0.955932  1.463528  1.952432   \n",
       "                         20          0.184037  0.406437  0.877663  0.371727   \n",
       "                         21          0.108236  0.140581  0.999843  0.306138   \n",
       "                         22          0.131048  0.206084  1.549073  1.455428   \n",
       "                         23          0.099588  0.119013  1.435766  0.894448   \n",
       "    \n",
       "                                          kurt  p25       p50       p75       p95  \\\n",
       "    day_of_week dow_name bin_of_day                                                 \n",
       "    0           Monday   0           -1.788794  0.0  0.250000  0.600000  0.706667   \n",
       "                         1            0.471937  0.0  0.000000  0.483333  0.990000   \n",
       "                         2           -1.643852  0.0  0.316667  0.666667  0.906667   \n",
       "                         3            5.068411  0.0  0.000000  0.000000  0.316667   \n",
       "                         4           13.000000  0.0  0.000000  0.000000  0.353333   \n",
       "    ...                                    ...  ...       ...       ...       ...   \n",
       "    6           Sunday   19           4.137205  0.0  0.291667  0.895833  2.276667   \n",
       "                         20          -0.295128  0.0  0.791667  1.150000  1.587500   \n",
       "                         21          -1.523378  0.0  0.366667  0.750000  0.871667   \n",
       "                         22           1.128710  0.0  0.000000  0.491667  1.095000   \n",
       "                         23          -1.265733  0.0  0.000000  0.600000  0.778333   \n",
       "    \n",
       "                                          p99  \n",
       "    day_of_week dow_name bin_of_day            \n",
       "    0           Monday   0           0.754667  \n",
       "                         1           0.998000  \n",
       "                         2           0.914667  \n",
       "                         3           0.396667  \n",
       "                         4           0.777333  \n",
       "    ...                                   ...  \n",
       "    6           Sunday   19          3.068667  \n",
       "                         20          1.917500  \n",
       "                         21          0.974333  \n",
       "                         22          1.285667  \n",
       "                         23          0.822333  \n",
       "    \n",
       "    [168 rows x 15 columns],\n",
       "    'arrivals':                                  count      mean  min  max     stdev  \\\n",
       "    day_of_week dow_name bin_of_day                                        \n",
       "    0           Monday   0            13.0  0.461538  0.0  1.0  0.518875   \n",
       "                         1            13.0  0.307692  0.0  1.0  0.480384   \n",
       "                         2            13.0  0.461538  0.0  2.0  0.660225   \n",
       "                         3            13.0  0.000000  0.0  0.0  0.000000   \n",
       "                         4            13.0  0.076923  0.0  1.0  0.277350   \n",
       "    ...                                ...       ...  ...  ...       ...   \n",
       "    6           Sunday   19           12.0  0.916667  0.0  4.0  1.311372   \n",
       "                         20           12.0  0.666667  0.0  2.0  0.778499   \n",
       "                         21           12.0  0.416667  0.0  2.0  0.668558   \n",
       "                         22           12.0  0.333333  0.0  1.0  0.492366   \n",
       "                         23           12.0  0.166667  0.0  1.0  0.389249   \n",
       "    \n",
       "                                          sem       var        cv      skew  \\\n",
       "    day_of_week dow_name bin_of_day                                           \n",
       "    0           Monday   0           0.143910  0.269231  1.124228  0.175204   \n",
       "                         1           0.133235  0.230769  1.561249  0.946212   \n",
       "                         2           0.183114  0.435897  1.430488  1.190649   \n",
       "                         3           0.000000  0.000000  0.000000  0.000000   \n",
       "                         4           0.076923  0.076923  3.605551  3.605551   \n",
       "    ...                                   ...       ...       ...       ...   \n",
       "    6           Sunday   19          0.378561  1.719697  1.430588  1.341703   \n",
       "                         20          0.224733  0.606061  1.167748  0.719333   \n",
       "                         21          0.192996  0.446970  1.604539  1.455194   \n",
       "                         22          0.142134  0.242424  1.477098  0.812404   \n",
       "                         23          0.112367  0.151515  2.335497  2.055237   \n",
       "    \n",
       "                                          kurt  p25  p50  p75   p95   p99  \n",
       "    day_of_week dow_name bin_of_day                                        \n",
       "    0           Monday   0           -2.363636  0.0  0.0  1.0  1.00  1.00  \n",
       "                         1           -1.339394  0.0  0.0  1.0  1.00  1.00  \n",
       "                         2            0.645297  0.0  0.0  1.0  1.40  1.88  \n",
       "                         3            0.000000  0.0  0.0  0.0  0.00  0.00  \n",
       "                         4           13.000000  0.0  0.0  0.0  0.40  0.88  \n",
       "    ...                                    ...  ...  ...  ...   ...   ...  \n",
       "    6           Sunday   19           1.265974  0.0  0.0  2.0  2.90  3.78  \n",
       "                         20          -0.792000  0.0  0.5  1.0  2.00  2.00  \n",
       "                         21           1.387877  0.0  0.0  1.0  1.45  1.89  \n",
       "                         22          -1.650000  0.0  0.0  1.0  1.00  1.00  \n",
       "                         23           2.640000  0.0  0.0  0.0  1.00  1.00  \n",
       "    \n",
       "    [168 rows x 15 columns],\n",
       "    'departures':                                  count      mean  min  max     stdev  \\\n",
       "    day_of_week dow_name bin_of_day                                        \n",
       "    0           Monday   0            13.0  0.230769  0.0  1.0  0.438529   \n",
       "                         1            13.0  0.461538  0.0  2.0  0.660225   \n",
       "                         2            13.0  0.461538  0.0  2.0  0.660225   \n",
       "                         3            13.0  0.230769  0.0  1.0  0.438529   \n",
       "                         4            13.0  0.000000  0.0  0.0  0.000000   \n",
       "    ...                                ...       ...  ...  ...       ...   \n",
       "    6           Sunday   19           12.0  0.333333  0.0  1.0  0.492366   \n",
       "                         20           12.0  0.916667  0.0  4.0  1.164500   \n",
       "                         21           12.0  0.666667  0.0  2.0  0.778499   \n",
       "                         22           12.0  0.416667  0.0  2.0  0.668558   \n",
       "                         23           12.0  0.333333  0.0  1.0  0.492366   \n",
       "    \n",
       "                                          sem       var        cv      skew  \\\n",
       "    day_of_week dow_name bin_of_day                                           \n",
       "    0           Monday   0           0.121626  0.192308  1.900292  1.451132   \n",
       "                         1           0.183114  0.435897  1.430488  1.190649   \n",
       "                         2           0.183114  0.435897  1.430488  1.190649   \n",
       "                         3           0.121626  0.192308  1.900292  1.451132   \n",
       "                         4           0.000000  0.000000  0.000000  0.000000   \n",
       "    ...                                   ...       ...       ...       ...   \n",
       "    6           Sunday   19          0.142134  0.242424  1.477098  0.812404   \n",
       "                         20          0.336162  1.356061  1.270364  1.847005   \n",
       "                         21          0.224733  0.606061  1.167748  0.719333   \n",
       "                         22          0.192996  0.446970  1.604539  1.455194   \n",
       "                         23          0.142134  0.242424  1.477098  0.812404   \n",
       "    \n",
       "                                         kurt  p25  p50  p75   p95   p99  \n",
       "    day_of_week dow_name bin_of_day                                       \n",
       "    0           Monday   0           0.094545  0.0  0.0  0.0  1.00  1.00  \n",
       "                         1           0.645297  0.0  0.0  1.0  1.40  1.88  \n",
       "                         2           0.645297  0.0  0.0  1.0  1.40  1.88  \n",
       "                         3           0.094545  0.0  0.0  0.0  1.00  1.00  \n",
       "                         4           0.000000  0.0  0.0  0.0  0.00  0.00  \n",
       "    ...                                   ...  ...  ...  ...   ...   ...  \n",
       "    6           Sunday   19         -1.650000  0.0  0.0  1.0  1.00  1.00  \n",
       "                         20          4.132081  0.0  1.0  1.0  2.90  3.78  \n",
       "                         21         -0.792000  0.0  0.5  1.0  2.00  2.00  \n",
       "                         22          1.387877  0.0  0.0  1.0  1.45  1.89  \n",
       "                         23         -1.650000  0.0  0.0  1.0  1.00  1.00  \n",
       "    \n",
       "    [168 rows x 15 columns]}},\n",
       "  'stationary': {'PatType_Severity': {'occupancy':                    count      mean  min        max     stdev       sem  \\\n",
       "    PatType Severity                                                         \n",
       "    ART     1         2160.0  0.492330  0.0   6.350000  1.003356  0.021589   \n",
       "            2         2160.0  0.838727  0.0  10.350000  1.565947  0.033694   \n",
       "    CAT     1         2160.0  0.719082  0.0   7.666667  1.124416  0.024194   \n",
       "            2         2160.0  1.037647  0.0   8.350000  1.498022  0.032232   \n",
       "    IVT     1         2160.0  2.321443  0.0  16.416667  3.329982  0.071650   \n",
       "            2         2160.0  3.536836  0.0  21.466667  4.991911  0.107409   \n",
       "    MYE     1         2160.0  0.549097  0.0   5.833333  1.013794  0.021813   \n",
       "            2         2160.0  0.847215  0.0   8.333333  1.455993  0.031328   \n",
       "    OTH     1         2160.0  0.343125  0.0   6.266667  0.778865  0.016759   \n",
       "            2         2160.0  0.534931  0.0   6.100000  1.113838  0.023966   \n",
       "    \n",
       "                            var        cv      skew       kurt  p25       p50  \\\n",
       "    PatType Severity                                                            \n",
       "    ART     1          1.006723  2.037973  2.252256   4.851844  0.0  0.000000   \n",
       "            2          2.452189  1.867052  1.913800   3.047896  0.0  0.000000   \n",
       "    CAT     1          1.264312  1.563684  1.947445   4.047071  0.0  0.000000   \n",
       "            2          2.244071  1.443673  1.611224   1.984996  0.0  0.250000   \n",
       "    IVT     1         11.088783  1.434445  1.428023   1.059173  0.0  0.425000   \n",
       "            2         24.919180  1.411406  1.355584   0.738548  0.0  0.666667   \n",
       "    MYE     1          1.027778  1.846292  2.055354   3.762445  0.0  0.000000   \n",
       "            2          2.119916  1.718565  1.918437   3.270166  0.0  0.000000   \n",
       "    OTH     1          0.606631  2.269916  2.947428  10.418587  0.0  0.000000   \n",
       "            2          1.240635  2.082211  2.444704   5.832510  0.0  0.000000   \n",
       "    \n",
       "                           p75        p95        p99  \n",
       "    PatType Severity                                  \n",
       "    ART     1         0.337500   2.883333   4.040167  \n",
       "            2         1.000000   4.416667   5.923500  \n",
       "    CAT     1         1.050000   3.200833   4.844000  \n",
       "            2         1.650000   4.300000   5.966667  \n",
       "    IVT     1         3.950000   9.433333  12.014500  \n",
       "            2         6.254167  14.220833  18.345667  \n",
       "    MYE     1         0.750000   2.916667   4.080333  \n",
       "            2         1.120833   4.150833   5.710667  \n",
       "    OTH     1         0.066667   2.000833   3.400000  \n",
       "            2         0.500000   3.068333   5.063667  ,\n",
       "    'arrivals':                    count      mean  min   max     stdev       sem        var  \\\n",
       "    PatType Severity                                                               \n",
       "    ART     1         2160.0  0.337500  0.0   5.0  0.791034  0.017020   0.625735   \n",
       "            2         2160.0  0.561111  0.0   8.0  1.174441  0.025270   1.379311   \n",
       "    CAT     1         2160.0  0.654630  0.0   7.0  1.086008  0.023367   1.179413   \n",
       "            2         2160.0  0.987963  0.0   8.0  1.495661  0.032182   2.237002   \n",
       "    IVT     1         2160.0  1.983333  0.0  17.0  2.980203  0.064124   8.881612   \n",
       "            2         2160.0  3.068056  0.0  23.0  4.497902  0.096779  20.231124   \n",
       "    MYE     1         2160.0  0.382407  0.0   5.0  0.808744  0.017401   0.654067   \n",
       "            2         2160.0  0.599537  0.0   7.0  1.154687  0.024845   1.333302   \n",
       "    OTH     1         2160.0  0.228241  0.0   6.0  0.626894  0.013489   0.392996   \n",
       "            2         2160.0  0.361574  0.0   5.0  0.864784  0.018607   0.747851   \n",
       "    \n",
       "                            cv      skew       kurt  p25  p50  p75   p95   p99  \n",
       "    PatType Severity                                                            \n",
       "    ART     1         2.343805  2.661981   7.188988  0.0  0.0  0.0   2.0   3.0  \n",
       "            2         2.093063  2.390140   5.864206  0.0  0.0  0.0   3.0   5.0  \n",
       "    CAT     1         1.658966  2.024500   4.725682  0.0  0.0  1.0   3.0   4.0  \n",
       "            2         1.513884  1.644256   2.146835  0.0  0.0  2.0   4.0   6.0  \n",
       "    IVT     1         1.502624  1.600821   1.881022  0.0  0.0  3.0   8.0  11.0  \n",
       "            2         1.466043  1.496197   1.328454  0.0  1.0  5.0  13.0  17.0  \n",
       "    MYE     1         2.114876  2.400693   5.864741  0.0  0.0  0.0   2.0   3.0  \n",
       "            2         1.925965  2.372931   6.066820  0.0  0.0  1.0   3.0   5.0  \n",
       "    OTH     1         2.746633  3.365270  13.395449  0.0  0.0  0.0   2.0   3.0  \n",
       "            2         2.391720  2.702151   7.102444  0.0  0.0  0.0   2.0   4.0  ,\n",
       "    'departures':                    count      mean  min   max     stdev       sem        var  \\\n",
       "    PatType Severity                                                               \n",
       "    ART     1         2160.0  0.337500  0.0   5.0  0.788101  0.016957   0.621104   \n",
       "            2         2160.0  0.561111  0.0   7.0  1.155756  0.024868   1.335773   \n",
       "    CAT     1         2160.0  0.654630  0.0   7.0  1.108800  0.023858   1.229437   \n",
       "            2         2160.0  0.987963  0.0  10.0  1.477904  0.031799   2.184200   \n",
       "    IVT     1         2160.0  1.983333  0.0  14.0  2.882877  0.062030   8.310977   \n",
       "            2         2160.0  3.068056  0.0  21.0  4.362935  0.093875  19.035200   \n",
       "    MYE     1         2160.0  0.382407  0.0   6.0  0.837996  0.018031   0.702238   \n",
       "            2         2160.0  0.599537  0.0   8.0  1.171413  0.025205   1.372209   \n",
       "    OTH     1         2160.0  0.228241  0.0   6.0  0.631311  0.013584   0.398554   \n",
       "            2         2160.0  0.361574  0.0   7.0  0.884903  0.019040   0.783053   \n",
       "    \n",
       "                            cv      skew       kurt  p25  p50  p75   p95   p99  \n",
       "    PatType Severity                                                            \n",
       "    ART     1         2.335115  2.638894   6.894015  0.0  0.0  0.0   2.0   3.0  \n",
       "            2         2.059764  2.166277   4.214449  0.0  0.0  0.0   3.0   5.0  \n",
       "    CAT     1         1.693782  2.048410   4.526321  0.0  0.0  1.0   3.0   5.0  \n",
       "            2         1.495910  1.676073   2.580821  0.0  0.0  2.0   4.0   6.0  \n",
       "    IVT     1         1.453551  1.454415   1.229618  0.0  0.0  3.0   8.0  11.0  \n",
       "            2         1.422052  1.382389   0.988846  0.0  0.0  6.0  12.0  16.0  \n",
       "    MYE     1         2.191371  2.602833   7.414518  0.0  0.0  0.0   2.0   4.0  \n",
       "            2         1.953863  2.414316   6.615847  0.0  0.0  1.0   3.0   5.0  \n",
       "    OTH     1         2.765988  3.545307  15.690640  0.0  0.0  0.0   2.0   3.0  \n",
       "            2         2.447362  2.996742   9.866890  0.0  0.0  0.0   2.0   4.0  },\n",
       "   '': {'occupancy':     count       mean  min        max      stdev      sem         var  \\\n",
       "    1  2160.0  11.220432  0.0  55.166667  14.542743  0.31291  211.491373   \n",
       "    \n",
       "             cv      skew      kurt       p25  p50    p75     p95      p99  \n",
       "    1  1.296095  1.070185 -0.259996  0.333333  2.0  22.25  41.035  47.4645  ,\n",
       "    'arrivals':     count      mean  min   max      stdev       sem         var        cv  \\\n",
       "    1  2160.0  9.164352  0.0  51.0  12.056234  0.259409  145.352781  1.315558   \n",
       "    \n",
       "          skew     kurt  p25  p50   p75   p95   p99  \n",
       "    1  1.19498  0.14769  0.0  2.0  17.0  35.0  41.0  ,\n",
       "    'departures':     count      mean  min   max      stdev       sem         var        cv  \\\n",
       "    1  2160.0  9.164352  0.0  46.0  11.991248  0.258011  143.790021  1.308467   \n",
       "    \n",
       "           skew      kurt  p25  p50   p75   p95   p99  \n",
       "    1  1.104257 -0.153161  0.0  2.0  18.0  33.0  39.0  }}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm.make_hills(scenario, stops_df, in_fld_name, out_fld_name, start, end, \n",
    "              catfield=cat_fld_name, \n",
    "              export_path = output, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's list the contents of the output folder containing the csv files created by hillmaker.  For Windows users, the following is the Linux `ls` command. The leading exclamation point tells Jupyter that this is an operating system command. To list the files in Windows, the equivalent would be:\n",
    "\n",
    "    !dir output\\example1*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./output/example1*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three groups of statistical summary files related to arrivals, departures and occupancy. In addition, the intermediate \"bydatetime\" files are also included. The filenames indicate whether or not the statistics are by category we well as if they are by day of week and time of day. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occupancy, arrival and departure summaries\n",
    "Let's look at the occupancy summaries (the structure is identical for arrivals and departures.) Here's a peek into the middle of **example1_occupancy_PatType_Severity_dow_binofday.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision', 2)\n",
    "pd.read_csv(\"./output/example1_occupancy_PatType_Severity_dow_binofday.csv\").iloc[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics by day and time but aggregated over all the categories are also available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./output/example1_occupancy_dow_binofday.csv\").iloc[20:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those files without \"dow_binofday\" in their name, the statistics are by category only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./output/example1_occupancy_PatType_Severity.csv\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's even a summary that aggregates over categories and time. Obviously, it contains a single row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./output/example1_occupancy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediate bydatetime files\n",
    "The intermediate tables used to compute the summaries we just looked at, are also available both by category and overall. Each row is a single time bin (e.g. date and hour of day). Note that the occupancy values are not necessarily integer since hillmaker's default behavior is to use fractional occupancy contributions for the bins in which the patient arrives and departs (e.g. if the patient arrived half-way through the time bin, they contribute 0.5 to total occupancy during that time bin). This behavior can be changed by specifying `edge_bins=2` when calling `make_hills`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./output/example1_bydatetime_datetime.csv\").iloc[100:125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./output/example1_bydatetime_PatType_Severity_datetime.csv\").iloc[100:125]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've used the previous version of Hillmaker, you'll recognize these files. The default behavior has changed to compute fewer percentiles but any percentiles you want can be computed by specifying them in the `percentiles` argument to `make_hills`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Compute totals for individual category fields, select percentiles, output to DataFrames\n",
    "We'll repeat the example above but use `totals=2` so that we get totals computed for each of the category fields in addition to overall totals. I'm also specifying a custom list of percentiles to compute. Instead of exporting CSV files, we'll capture the results as a dictionary of DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Required inputs\n",
    "scenario = 'example2'\n",
    "in_fld_name = 'InRoomTS'\n",
    "out_fld_name = 'OutRoomTS'\n",
    "start = '1/1/1996'\n",
    "end = '3/30/1996 23:45'\n",
    "\n",
    "# Optional inputs\n",
    "cat_fld_name = ['PatType', 'Severity']\n",
    "totals= 2\n",
    "percentiles=[0.5, 0.95]\n",
    "verbose = 0 # Silent mode\n",
    "output = './output'\n",
    "export_bydatetime_csv = True\n",
    "export_summaries_csv = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll call `make_hills` and tuck the results (a dictionary of DataFrames) into a local variable. Then we can explore them a bit with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example2_dfs = hm.make_hills(scenario, stops_df, in_fld_name, out_fld_name, start, end, cat_fld_name, \n",
    "                             totals=totals, export_path=output, verbose=verbose,\n",
    "                             export_bydatetime_csv=export_bydatetime_csv, \n",
    "                             export_summaries_csv=export_summaries_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `example2_dfs` return value is several nested dictionaries eventually leading to pandas DataFrames as values. Let's explore the key structure. It's pretty simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example2_dfs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the 'summaries' key first. As you might guess, this will eventually lead to the statistical summary DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2_dfs['summaries'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2_dfs['summaries']['nonstationary'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2_dfs['summaries']['nonstationary']['Severity_dow_binofday'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example2_dfs['summaries']['nonstationary']['Severity_dow_binofday']['occupancy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stationary summaries are similar except that there are no day of week and time bin of day related files.\n",
    "\n",
    "Now let's look at the 'bydatetime' key at the top level. Yep, gonna lead to bydatetime DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2_dfs['bydatetime'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2_dfs['bydatetime']['PatType_Severity_datetime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3 - Workload hills instead of occupancy\n",
    "Assume that we are doing a staffing analysis and want to look at the distribution of workload by time of day and day of week. In order to translate patients to workload, we'll use simple staff to patient ratios based on severity. For example, let's assume that for `Severity=1` we want to have a 1:4 staff to patient ratio and for `Severity=2` we need a 1:2 ratio. Let's create a new field called `workload` using these ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_to_workload = {'1':0.25, '2':0.5}\n",
    "stops_df['workload'] = stops_df['Severity'].map(lambda x: severity_to_workload[str(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create workload hills. I'm just going to compute overall workload by not specifiying a category field. Notice the use of the `occ_weight_field` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required inputs\n",
    "scenario = 'example3'\n",
    "in_fld_name = 'InRoomTS'\n",
    "out_fld_name = 'OutRoomTS'\n",
    "start = '1/1/1996'\n",
    "end = '3/30/1996 23:45'\n",
    "\n",
    "# Optional inputs\n",
    "occ_weight_field = 'workload'\n",
    "verbose = 0\n",
    "output = './output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example3_dfs = hm.make_hills(scenario, stops_df, in_fld_name, out_fld_name, start, end, \n",
    "              occ_weight_field=occ_weight_field, \n",
    "              export_path = output, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2_dfs['summaries']['stationary']['Severity']['occupancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example3_dfs['summaries']['stationary']['']['occupancy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the overall mean workload in example3 by doing a weighted average of the mean occupancies by Severity from example2 with the workload ratios as weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_occ = np.asarray(example2_dfs['summaries']['stationary']['Severity']['occupancy'].loc[:,'mean'])\n",
    "mean_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = [severity_to_workload[str(i+1)] for i in range(2)]\n",
    "ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_mean_workload = np.dot(mean_occ, ratios)\n",
    "overall_mean_workload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 4 - Running via a Python script\n",
    "Of course, you don't have to run Python statements through a Jupyter notebook. You can create a  Python script and run that directly in a terminal. An example, `test_shortstay2_multicats.py`, can be found in the `scripts` subfolder of the hillmaker-examples project. You can run it from a command prompt like this:\n",
    "\n",
    "```sh\n",
    "python test_shortstay2_multicats.py\n",
    "```\n",
    "\n",
    "There is another example in that folder as well, `test_obsim_log.py`, that is slightly more complex in that the input data has raw simulation times (i.e. minutes past t=0) and we need to do some datetime math to turn them into calendar based inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More elaborate versions of scripts like `test_shortstay2_multicats.py` can be envisioned. For example, an entire folder of input data files could be processed by enclosing the `hm.make_hills` call inside a loop over the collection of input files:\n",
    "\n",
    "    for log_fn in glob.glob('logs/*.csv'):\n",
    "\n",
    "            # Read the log file and filter by included categories\n",
    "            stops_df = pd.read_csv(log_fn, parse_dates=[in_fld_name, out_fld_name])\n",
    "\n",
    "            hm.make_hills(scenario, df, in_fld_name, out_fld_name, start, end, cat_fld_name)\n",
    "            ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User interface plans\n",
    "Over the years, I (and many others) have used Hillmaker in a variety of ways, including:\n",
    "\n",
    "- MS Access form based GUI\n",
    "- run main Hillmaker sub from Access VBA Immediate Window\n",
    "- run Hillmaker main sub (and/or components subs) via custom VBA procedures\n",
    "\n",
    "I'd like users to be able to use the new Python based version in a number of different ways as well. As I've shown in this Jupyter notebook, it can be used by importing the `hillmaker` module and then calling Hillmaker functions via:\n",
    "\n",
    "- an Jupyter notebook (or any Python terminal such as an IPython shell or QT console, or IDLE)\n",
    "- a Python script with the input arguments set and passed via Python statements\n",
    "\n",
    "While these two options provide tons of flexibility for power users, I also want to create other interfaces that don't require users to write Python code. At a minimum, I plan to create a command line interface (CLI) as well as a GUI that is similar to the old Access version.\n",
    "\n",
    "### A CLI for Hillmaker\n",
    "Python has several nice tools for creating CLI's. Both `docopt` and `argparse` are part of the standard library. Layered on top of these are tools like [Click](http://click.pocoo.org/5/). See http://docs.python-guide.org/en/latest/scenarios/cli/ for more. A well designed CLI will make it easy to use Python from the command line in either Windows or Linux. \n",
    "\n",
    "### A GUI for Hillmaker\n",
    "This is uncharted territory for me. Python has [a number of frameworks/toolkits for creating GUI apps](https://wiki.python.org/moin/GuiProgramming). This is not the highest priority for me but I do plan on creating a GUI for Hillmaker. If anyone wants to help with this, awesome.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
